{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db75b9c",
   "metadata": {},
   "source": [
    "# 1. Problem Statement\n",
    "\n",
    "In this notebook, we aim to analyze air quality and global air pollution data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950d5ff",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Description\n",
    "\n",
    "We will load the datasets and provide an overview of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c057704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "air_quality_data = pd.read_csv('AirQuality.csv')\n",
    "global_air_pollution_data = pd.read_csv('global air pollution dataset.csv')\n",
    "\n",
    "# Display the first few rows of both datasets\n",
    "air_quality_data.head(), global_air_pollution_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b7f4d",
   "metadata": {},
   "source": [
    "# 3. Naive Submission 1\n",
    "\n",
    "This is a simple initial submission with basic predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704de85f",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Pipeline\n",
    "\n",
    "We will describe the steps followed in creating the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fa3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Reload the data with the correct delimiter\n",
    "air_quality_data = pd.read_csv('AirQuality.csv', delimiter=';')\n",
    "\n",
    "# Drop unnamed columns if present (from trailing delimiters)\n",
    "air_quality_data = air_quality_data.loc[:, ~air_quality_data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Drop rows with missing target values\n",
    "air_quality_data = air_quality_data.dropna(subset=['CO(GT)'])\n",
    "\n",
    "# Data Preprocessing\n",
    "# Use 'CO(GT)' as the target column (replace with another if needed)\n",
    "X = air_quality_data.drop(columns=['CO(GT)'])\n",
    "y = air_quality_data['CO(GT)']\n",
    "\n",
    "# Fill missing values for features\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "# Drop non-numeric columns before scaling\n",
    "X = X.select_dtypes(include=['number'])\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59cf83",
   "metadata": {},
   "source": [
    "# 5. Naive Submission 2\n",
    "\n",
    "We can now make another submission based on the refined pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c6087",
   "metadata": {},
   "source": [
    "# 6. EDA and Data Preprocessing\n",
    "\n",
    "Exploration of the dataset to prepare it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86434ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EDA - Basic statistics and visualizations\n",
    "air_quality_data.describe()\n",
    "\n",
    "# Plotting a histogram for distribution of a column\n",
    "plt.hist(air_quality_data['CO(GT)'], bins=20)\n",
    "plt.title('CO(GT) Distribution')\n",
    "plt.xlabel('CO(GT)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b650b73",
   "metadata": {},
   "source": [
    "# 7. Model Training\n",
    "\n",
    "Train the model with the data and process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1889be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example using RandomForest, but can be extended to other models as well\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01dd5b9",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation\n",
    "\n",
    "Evaluating the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101f11e",
   "metadata": {},
   "source": [
    "## 8.1 Model Evaluation using Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddf669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52099aa",
   "metadata": {},
   "source": [
    "## 8.2 Model Evaluation using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c83ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f4eee",
   "metadata": {},
   "source": [
    "# 9. Decision Tree with Gridsearch\n",
    "\n",
    "Implementing Decision Tree and tuning hyperparameters with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model and parameters for GridSearch\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa92c55",
   "metadata": {},
   "source": [
    "# 6. EDA and Data Preprocessing\n",
    "\n",
    "Exploring the data to identify key patterns, visualizations, and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088173f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert 'CO(GT)' to numeric (replace comma with dot and coerce errors)\n",
    "air_quality_data['CO(GT)_num'] = pd.to_numeric(air_quality_data['CO(GT)'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Pairplot to visualize the relationships between features\n",
    "sns.pairplot(air_quality_data.select_dtypes(include=['float64']))\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for detecting outliers in the 'CO(GT)' column\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=air_quality_data['CO(GT)_num'])\n",
    "plt.title('Boxplot for CO(GT)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224913c",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ee988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detecting outliers using the IQR method\n",
    "# Convert 'CO(GT)' to numeric if not already\n",
    "co_numeric = pd.to_numeric(air_quality_data['CO(GT)'], errors='coerce')\n",
    "Q1 = co_numeric.quantile(0.25)\n",
    "Q3 = co_numeric.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identifying outliers\n",
    "outliers = air_quality_data[(co_numeric < (Q1 - 1.5 * IQR)) | (co_numeric > (Q3 + 1.5 * IQR))]\n",
    "print(f'Number of outliers: {outliers.shape[0]}')\n",
    "sns.boxplot(x=co_numeric)\n",
    "plt.title('Boxplot with Outliers Detected')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953262f",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation\n",
    "\n",
    "We will compare model performances with various metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87aff3",
   "metadata": {},
   "source": [
    "### 8.1 Model Evaluation using Accuracy, Precision, Recall, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model with accuracy, precision, recall, and f1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Displaying the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8049d",
   "metadata": {},
   "source": [
    "### 8.2 ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Binarize the output\n",
    "classes = np.unique(y_test)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "y_score = model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(classes)):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve (Multiclass)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8713202",
   "metadata": {},
   "source": [
    "# 9. Decision Tree with Gridsearch\n",
    "\n",
    "We will implement Decision Tree and tune its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example of hyperparameter tuning using GridSearchCV for Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters from GridSearch\n",
    "print(f'Best parameters from GridSearch: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca180435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
